\documentclass[10pt,journal,compsoc]{IEEEtran}

% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/tex-archive/macros/latex/contrib/oberdiek/
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
\ifCLASSOPTIONcompsoc
  % IEEE Computer Society needs nocompress option
  % requires cite.sty v4.0 or later (November 2003)
  \usepackage[nocompress]{cite}
\else
  % normal IEEE
  \usepackage{cite}
\fi
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/cite/
% The documentation is contained in the cite.sty file itself.
%
% Note that some packages require special options to format as the Computer
% Society requires. In particular, Computer Society  papers do not use
% compressed citation ranges as is done in typical IEEE papers
% (e.g., [1]-[4]). Instead, they list every citation separately in order
% (e.g., [1], [2], [3], [4]). To get the latter we need to load the cite
% package with the nocompress option which is supported by cite.sty v4.0
% and later. Note also the use of a CLASSOPTION conditional provided by
% IEEEtran.cls V1.7 and later.





% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
    \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
    \graphicspath{{./pics/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  %  \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/graphics/
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/tex-archive/info/epslatex/
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex






% *** MATH PACKAGES ***
%
\usepackage[cmex10]{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/





% *** SPECIALIZED LIST PACKAGES ***
%
\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/




% *** ALIGNMENT PACKAGES ***
%
\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
\ifCLASSOPTIONcompsoc
  \usepackage[caption=false,font=footnotesize,labelfont=sf,textfont=sf]{subfig}
\else
  \usepackage[caption=false,font=footnotesize]{subfig}
\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a sans serif font rather
% than the serif font used in traditional IEEE formatting and thus the need
% to invoke different subfig.sty package options depending on whether
% compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/subfig/




% *** FLOAT PACKAGES ***
%
\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure. The latest version and documentation can be found at:
% http://www.ctan.org/tex-archive/macros/latex/base/


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Do not use the stfloats baselinefloat ability as IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/dblfloatfix/




%\ifCLASSOPTIONcaptionsoff
%  \usepackage[nomarkers]{endfloat}
% \let\MYoriglatexcaption\caption
% \renewcommand{\caption}[2][\relax]{\MYoriglatexcaption[#2]{#2}}
%\fi
% endfloat.sty was written by James Darrell McCauley, Jeff Goldberg and
% Axel Sommerfeldt. This package may be useful when used in conjunction with
% IEEEtran.cls'  captionsoff option. Some IEEE journals/societies require that
% submissions have lists of figures/tables at the end of the paper and that
% figures/tables without any captions are placed on a page by themselves at
% the end of the document. If needed, the draftcls IEEEtran class option or
% \CLASSINPUTbaselinestretch interface can be used to increase the line
% spacing as well. Be sure and use the nomarkers option of endfloat to
% prevent endfloat from "marking" where the figures would have been placed
% in the text. The two hack lines of code above are a slight modification of
% that suggested by in the endfloat docs (section 8.4.1) to ensure that
% the full captions always appear in the list of figures/tables - even if
% the user used the short optional argument of \caption[]{}.
% IEEE papers do not typically make use of \caption[]'s optional argument,
% so this should not be an issue. A similar trick can be used to disable
% captions of packages such as subfig.sty that lack options to turn off
% the subcaptions:
% For subfig.sty:
% \let\MYorigsubfloat\subfloat
% \renewcommand{\subfloat}[2][\relax]{\MYorigsubfloat[]{#2}}
% However, the above trick will not work if both optional arguments of
% the \subfloat command are used. Furthermore, there needs to be a
% description of each subfigure *somewhere* and endfloat does not add
% subfigure captions to its list of figures. Thus, the best approach is to
% avoid the use of subfigure captions (many IEEE journals avoid them anyway)
% and instead reference/explain all the subfigures within the main caption.
% The latest version of endfloat.sty and its documentation can obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/endfloat/
%
% The IEEEtran \ifCLASSOPTIONcaptionsoff conditional can also be used
% later in the document, say, to conditionally put the References on a
% page by themselves.




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/url/
% Basically, \url{my_url_here}.





% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )

\usepackage{enumitem}
\usepackage{algorithm}
\usepackage{multirow}
\usepackage{slashbox}
%\usepackage{ulem}
%\usepackage[numbers,sort&compress]{natbib}
\renewcommand{\arraystretch}{1.3}


\usepackage{color}

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
\floatname{algorithm}{Procedure}

\begin{document}
\title{Efficient, Robust and Exact Boolean Operations on N Triangular Mesh Primitives}
\author{Rui~Wang,~
        Xudong~Jiang,~
        Hongbo~Fu,~
        Bin~Sheng,~and
        Enhua~Wu
\IEEEcompsocitemizethanks{

\IEEEcompsocthanksitem R. Wang and B. Sheng are with the Department of Computer Science and Engineering, Shanghai Jiao Tong University. Email:\{jhcz,shengbin\}@sjtu.edu.cn

\IEEEcompsocthanksitem X. Jiang is with Autodesk China Research \& Development Center. Email: xudong.jiang@autodesk.com

\IEEEcompsocthanksitem H. Fu is with the School of Creative Media, City University of Hong Kong. Email: hongbofu@cityu.edu.hk


\IEEEcompsocthanksitem E. Wu is currently a research professor at State Key Lab. of Computer Science, Institute of Software, Chinese Academy of Sciences. Email: ehwu@umac.mo}
}

%\markboth{Journal of \LaTeX\ Class Files,~Vol.~13, No.~9, September~2014}%
%{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for Computer Society Journals}

\IEEEtitleabstractindextext{
\begin{abstract}
  In this paper, we propose an efficient non-incremental approach to evaluate the boundary of constructive solid geometry (CSG). The face membership classification step is a bottleneck in many existing CSG evaluation approaches. The key idea of our approach is to use local coherence of space labels to accelerate this step. We employ a two-level grouping scheme to group faces that share the same space labels. Therefore, these common space labels can be shared within each group to avoid repetitive computation. Our method is optimized for a non-incremental evaluation. It generates the entire result model at once, rather than performing a step-by-step evaluation of Boolean operations. To achieve a robust evaluation, our approach introduces plane-based geometry into the intersection computation step. Comparison experiments with state-of-the-art techniques show that our method can more efficiently perform boundary evaluation of both trivial and complicated CSG with massive faces while maintaining robustness.
\end{abstract}


\begin{IEEEkeywords}
Boolean operations, triangle mesh, CSG evaluation, plane-based geometry.
\end{IEEEkeywords}

}



\maketitle


\IEEEdisplaynontitleabstractindextext
\IEEEpeerreviewmaketitle

\IEEEraisesectionheading{\section{Introduction}\label{sec:introduction}}
\IEEEPARstart{C}{onstructive} solid geometry (CSG) has long been a popular modeling tool of computer-aided design and computer-aided manufacturing (CAD/CAM). It constructs complex models by combining primitives using a series of regularized Boolean operations \cite{requicha1977mathematical}: union, intersection and difference. CSG is often represented by a binary tree, called a CSG tree, whose leaves are primitives and whose internal nodes are Boolean operations.

CSG can be converted into the widely-used  boundary representation (i.e., triangle mesh) through boundary evaluation. It is an classical topic with history of over three decades. However, one always have to make a bargain between robustness and efficiency of the boundary evaluation. One could use rational number arithmetic to avoid errors and thus ensure unconditional robustness, which could be over 20 times slower than a non-robust one [?]. On the other hand, using an approximate method for boundary evaluation can be very fast, but lack exactness.

Most recent methods [???] try to find a faster way to evaluate boundary of CSG, yet for robustness, the answers are often ambiguous workarounds, like setting a tolerance [?], using higher precision float point number [?] or rotating the primitive with small angle to avoid coplanar cases [?], etc. These tricks are often too vague to implement, heavily depend on the experiments, thus not reliable. Campen et. al. [?] gave a good paradigm of a unconditional robust and exact boundary evaluation methods. It proved to be fairly efficient, and never crashed with legal inputs. Since then, few exact evaluation methods declare themselves as an unconditional robust one.

We prove that exact boundary evaluation of CSG can be even faster, while keeping unconditional robust. We adapt the plane-based techniques of Campen et. al.'s method for robustness, but use a framework very different from Campen et. al.'s, taking advantage of the recent popular idea of using geometry connectivity for face classification acceleration. In addition, unlike many other methods, our method can perform boundary evaluation directly for CSG with more than two primitives. That is, we do not incrementally generate the intermediate meshes of each Boolean operation. In opposite, we generate the final mesh directly. In this way, extra complexity of method is introduced, but we can save much computation time. The experiment shows that our method is much faster than Campen et. al.'s method, while only about twice slower than the state-of-art non-robust methods [??].



\section{Related Work}

\subsection{Plane-based geometry representation}

The primary information of commonly used representation of solids are the vertex coordinates. In this way, edges and faces are implicitly represented by combination of vertices. In contrast, in plane-based representation, the primary elements are planes. Vertices and edges are all implicitly represented by plane intersections.



The concept of plane-based representation of polygonal meshes was first described by Sugihara and Iri \cite{sugihara1990solid}. Plane-based representation provides one important advantage
when it comes to tasks that involve changing the topology of solids represented by meshes like the evaluation of Boolean expressions: no new primary geometry information has to be constructed to obtain the resulting polyhedron C it is composed of a subset of the planes of the input polyhedra. Hence, opposed to the case of using vertex coordinates, that inevitably necessitates the construction of new geometry information, only geometric decision predicates are required to compose the output polyhedron from the face planes of the input. Since the input is usually given in a numerical representation with finite precision, we can determine an upper bound on the precision that is needed to make correct decisions. The a priori knowledge of this upper bound allows us to use fixed precision predicates that are specifically tailored to the precision required in the worst case, resulting in a vastly better performance compared to techniques for arbitrary numerical precision, that are usually required when
constructions are part of the processing. Our processing is rigorously based on this paradigm of plane-based geometry representation that allows us to perform fully robust, exact computations using only fast fixed precision predicates. These predicates take planes as arguments and check coincidence and co-orientation of planes, orientation of a plane with respect to a point defined by the intersection of three planes, and whether three planes intersect in a unique point. The latter one can also be used in negated form to check if three planes, that are known to intersect in a common point, even intersect in a common line. We implement them using filtering techniques proposed by Shewchuk.

\subsection{Exact evaluation methods}


CSG evaluation has had notorious problems with robustness since its inception in the 1980s \cite{requicha1985boolean, laidlaw1986constructive}. The non-robustness is inherited from the building blocks of CSG: Boolean operations on solids. Many researchers have attempted to solve such an issue using arbitrary precision arithmetic \cite{banerjee1996topologically, fortune1995polyhedral, keyser2004esolid, granados2003boolean, hachenberger2005boolean} and exact interval computation \cite{fang1993robustness, hu1996robust, segal1990using}. However, these methods are often too expensive in computation time and memory to be practical for evaluation of CSG with massive faces. For example, in the Computational Geometry Algorithms Library (CGAL) \cite{cgal:hk-bonp3-15a}, the state-of-the-art robust Boolean operation algorithm \cite{hachenberger2005boolean} (implemented with arbitrary precision arithmetic) is more than 20 times slower than its non-robust version.


\subsection{Approximative evaluation methods}

With the development of general-purpose computing on graphics processing units (GPGPUs), many researchers  \cite{wang2011approximate, zhao2011parallel, museth2002level, chen1999volumetic, eisemann2008single} have tried to utilize the grand computation power of graphics hardware for Boolean operations. These methods often have good performance and are suitable for interactive applications, such as digital sculpting. However, owing to the paralleled features of graphics hardware, these methods are usually voxel-based and support only approximate evaluation that inevitably suffers from geometric detail loss, especially at the intersection areas of primitives.

\section{Motivation and Overview}

\label{sec:overview}
Our method is designed for boundary evaluation of Boolean operations on arbitrary number of primitives. Input primitives should be watertight and non-manifold  triangle meshes, represented by halfedge structures\cite{mcguire2000half}. Our method is unconditional robust, exact, while keeping good performance. In this section, we first introduce the motivation of our method, then describe where we start to design our boundary evaluation method. At last, we give the overview of the method.


\subsection{Motivation}
\label{sec:paradigm}

The boundary evaluation is in essence a process of selection. In other words, given a Boolean function, it reserves those primitive faces that pass the function and drop the others to generate the final mesh. Unfortunately, for B-reps primitives such as triangle mesh, not all the facets from the input primitives can be classified in a whole, since some of them intersect other primitives. Therefore, we need an extra step aiming at detecting the intersection between primitives and performing the tessellation. In general, most of the boundary evaluation methods follow the two-step paradigm  \cite{wang2011approximate} above, which consists of intersection computation and face classification.

During the intersection computation, primitive facets are tested in pairs to compute their intersection. Each input primitives are tessellated according to the intersection test results, making every face be either inside, outside or on the boundary of other primitives. They are what we called \emph{non-intersected meshes}. Every face of non-intersected meshes can be classified in a whole during classification. Unfortunately, under common float-point coordinate system, intersection test is error-prone. There are mainly two causes: first, there are a large amount of degenerate cases which are hard to be exactly detected; second, when there are intersections, new vertices are introduced into the geometry, whose coordinates usually can not be exactly represented by float-point number.

Face classification is to evaluate whether a given face $x$ belongs to the final geometry according to the n-primitive Boolean function $\Phi$ :
\begin{equation}
\lambda_\Phi(x) = \Phi(\lambda_1(x), \lambda_2(x), \cdots, \lambda_n(x)).
\end{equation}
The parameter $\lambda_i(x)$ is space indicator with respect to primitive $P_i$. This means to classify a face, one has to know the space indicators with respect to all the primitives (or the whole indicator vector $\vec{\lambda}(x)$ for short). A space indicator has four conditions: completely inside (\emph{in}), completely outside (\emph{out}), on the boundary with consistent normals (\emph{same}) or opposite normals (\emph{oppo}). The rules of Boolean function evaluation by these indicators are described in \cite{douze2015quickcsg}\cite{feito2013fast}.

Face classification also suffers from robustness and exactness problems. Many methods classify face according to the indicators of its barycenter, and use point-in-polyhedron test to compute these indicators. However, coordinates of barycenters cannot be exactly represented and have the potential to generate false classification. In addition, to classify a single face, all the components of its space indicator vector must be figured out. Considering the large amount of faces, acceleration is usually necessary. Many algorithms take the benefits of the local coherence of indicators, classifying neighboring faces together. While this does improve the performance, it can make the exactness problem worse because the false classification can be propagated to neighboring faces.

We want to develop a new boundary evaluation method based on the two-step paradigm, keeping unconditional robust, exact and as fast as possible. Combined with the analysis above, we think our method should includes the following features:
\begin{itemize}
    \item It has to avoid errors when introducing new vertices during intersection computation. All degenerate cases of intersection have to be well resolved.
    \item Face classification has to be exact. On the other hand, acceleration using local coherence of indicators may be helpful.
    \item The exactness and robustness should not rely on arbitrary precision arithmetic, because it is too slow. Instead, we choose the plane-based techniques from \cite{bernstein2009fast}\cite{campen2010exact} to ensure good performance.
\end{itemize}

\subsection{Linked halfedge}

\label{sec:meshes}
We make an essential observation that the non-intersected meshes, as intermediate result of intersection computation, plays a very important role of the method design. It is a bridge that controls the complexity of intersection computation and facilitates the face classification. After the non-intersected meshes is determined, all things left are how to construct such a data structure and how to classify according to it.

Our non-intersected mesh, called linked halfedge, is a variance of halfedge, a well-known data structure to represent solids. Halfedge has two advantages: first, since halfedge is popular, using it as the intermediate data structure can avoid unnecessary conversion, which has the potential to create simpler algorithm and better performance and result topology; second, the geometry connectivity, by which we accelerate classification using local coherence of space indicators, can be easily retrieved through halfedge.

However, naive halfedge is far from enough. The vertex coordinates in halfedge are usually represented by float point number, which cannot exactly represent the newly introduced intersection points. Therefore, we utilize plane-based representation to avoid computing new coordinates. In addition, we detect all coincident vertices among primitives and linked them together (that is why it is called linked halfedge). This information is used for avoiding repetitive vertices, reconstructing geometry connectivity, and ensuring the topology correctness.

Enlightened by Feito et. al. \cite{feito2013fast}, we found that the the topology near intersection lines between faces can benefit point-in-polyhedron test by dramatically reducing the number of faces needing traversing. Therefore, we add extra information into the linked halfedge, called \emph{intersection context}, to facilitate afterwards face classification. Intersection context identifies where an intersection lies on the surface of the related primitives. An edge of linked halfedge has intersection context only if it is coincident with a certain intersection line segment between primitives. We will give the definition and usage of intersection context in details in the following sections.

To give a overall impression of how we design linked halfedge, we summarize the above content and highlight the following features:

\begin{itemize}
  \item Each input primitive mesh is tessellated into a linked halfedge. Faces in a linked halfedge must not cross any other linked halfedges.
  \item Coincident vertices between different linked halfedge should be linked, that is, coincident vertices are shared among linked halfedges.
  \item If a certain edge of linked halfedge is coincident with intersection line segment(s), it should be associated with the corresponding intersection context(s).
\end{itemize}


\subsection{Method overview}

\subsubsection{Space division}

This step is the preparation of intersection detection. As intersection detection is performed between each pair of faces, localization is necessary to filter invalid pairs beforehand. In general, any space division data structure can be applied in this step. We use the adaptive octree for its simplicity. Our implementation is akin to the implementation in \cite{ogayar2015deferred}. Intersection between triangle faces and octree leaves can be efficiently detected using the separating axis theorem \cite{gottschalk1996obbtree}. Octree leaves are classified into two types: if all faces that intersect a leaf belong to the same primitive, we call it a \emph{non-critical cell}. Otherwise, it is a \emph{critical cell}.

The difference between our space division and many others \cite{ogayar2015deferred}\cite{feito2013fast} is the octree node subdivision termination criterion. In our method, we do not need subdivide any non-critical cell no matter how many faces it contains. This is because subdividing non-critical cells benefits only the ray-casting point-in-polyhedron test, which rarely appears in our method. This simplification can bring large performance advantage, especially for those cases where intersections between primitives are not complex and limited in small regions.

\subsubsection{Intersection detection}

This step is to detect intersections between primitives in a robust and exact way. Our algorithm is largely based on vertex-based M\"{o}ller's algorithm \cite{moller1997fast}, which is very efficient to compute intersection between two triangles. However, naive implementation of M\"{o}ller's algorithm always incurs robustness issues when computing the coordinates of new vertices. To avoid an unexpected failure caused by numeric errors, we integrate plane-based representation of polyhedra \cite{sugihara1990solid} into the implementation of M\"{o}ller's algorithm. Adaptive precision predicate technique \cite{shewchuk1997adaptive} is applied for efficiency of plane-based geometry computation. Moreover, to make our method robust, we classify all the intersection cases into three major classes and respectively discuss how to each condition. Details are provided in Section \ref{section:isect}.

\subsubsection{Tessellation}

Once all intersections are detected, we need to tessellate the input primitives and construct the linked halfedges.. In many methods like \cite{ogayar2015deferred}, constraint Delaunay triangulation (CDT) is applied to perform tessellation, since the intersections are naturally the constraints of CDT. However, for a CSG with more than two primitives, the intersection vertices may be generated by intersections of three faces from different primitives, which cannot be computed during the previous step. Also, intersection line segments may overlap or intersect with each other, and cannot be used for constraints of CDT directly. Finally, as our intersection vertices are represented exactly by planes, implementation of CDT could be complex and inefficient, as most CDT methods were not designed to handle planes. Therefore, we design a simple structure, called tessellation graph, to guide the tessellation of each single face, and develop a very fast but exact method to construct linked halfedges from tessellation graphs, which is suitable for dealing with plane-based representation of intersections. Details are shown in section \ref{sec:tessellation}.

\subsubsection{Face classification}

This step is to choose faces from the linked halfedges to generate the final mesh. Literally compute all the space indicators of each face is unacceptable slow for large CSG trees. Enlightened by Feito et. al. \cite{feito2013fast}, we utilize the geometry connectivity to accelerate this process. In Feito et. al.'s method, the faces of tessellated meshes are first grouped according to whether they have the same indicator vector. After the grouping, each group is classified as a whole. This is based on the observation that indicators of faces are spatially coherent. That is, if a face $f$ is outside of primitive $M_0$, the neighbor of $f$ are likely to be out of $M_0$, too. Different from Feito et. al.'s method, we also consider the condition when the number of primitives is larger than two. In this condition, space vector of a face may be partly the same with its neighborhoods'. That is, we allow space indicators not only share within faces of the same group, but also among different groups and even primitives. This is useful when the number of primitives is large, or intersections between primitives is complex. Details will be shown in section \ref{sec:classification}.


\section{Plane-based geometry}

Vertex coordinates are commonly used in geometry computation. However, vertex coordinates suffer from inexact representation of intersection point between primitives. Therefore, we choose to use planes-based representation of polyhedrons and implicitly represent vertex by plane intersection. We start with a quick review of the basic conception of plane-based representation. After that, we introduce two substrates related to plane-based representation used in our method, since these two are rarely seen in related researches. Other substrates of plane-based representation can be seen in \cite{bernstein2009fast}.

\subsection{Conversion}

\label{sec:convert}

As we discussed in Section \ref{sec:paradigm}, one of the problem in Boolean evaluation under vertex-based representation is it inevitably introduces new vertices, whose coordinates cannot be exactly represented using standard float-point number. On the other hand, if plane-based representation is used, no new geometry information needs to be constructed---the result mesh is composed of the planes of the input primitives. Therefore, we can use only geometric decision predicates to perform the Boolean operation.

Using plane-based representation, each face of polyhedron is represented by a supporting plane $S$, where the face lies, and a list bounding planes $\{B_i\}$, each corresponding an edge of the face. Edge line is represented by intersection of $S$ and the related $B_i$. Corner point is then the intersection of $S$ and two consecutive bounding planes $B_i$ and $B_{i+1}$. Efficient and exact conversion from the vertex-based representation to plane-based representation is described in detail in \cite{campen2010exact}. If the input vertex coordinates precision is $L$, the maximum precision $P$ required to represent the plane coefficients is:
\begin{equation}
\label{eq:precision}
P = (L-1)+2(K-1)+3+1,
\end{equation}
where $K$  is the maximum bits to represent edge vector coordinates. If the plane coefficient has $M$ bit precision, $M$ have to greater than $P$ for exact representation. We rigorously enforce the criterion to $M \ge P+1$, and we will explain it in section \ref{sec:embed}.


Let $\delta = 2^{K-L-1}$ be the relative length (in max-norm) of the
longest edge in the mesh (relative to the bounding box). If we use IEEE 754 double precision ($M=53$) and assume $\delta \le 2^{-5.5}$, the maximum input precision $L$ can reach to 20, which is enough for most CAD application. As the precision of input coordinates is finite, we can determine in advance the upper boundary of precision needed to perform a precise decision, with which we can use fixed precision predicates techniques to gain much performance while keeping exactness. We implement the predicates using filtering techniques proposed by Shewchuk \cite{shewchuk1997adaptive}.


\subsection{Substrates}
\label{sec:substrates}
Our method rigorously follows the paradigm of plane-based geometry. All decision predicates are computed using planes as input. These predicates include checking coincidence and co-orientation of planes, orientation of a plane with respect to a point, and whether three planes intersect in a unique point, etc. We omit the discussion of the predicates which is already in prior work \cite{bernstein2009fast,banerjee1996topologically}, and focus on specific predicates in our method in the following.

Before we start the discussion, we first introduce several regulations frequently used in the rest of our paper. A plane $P_x$ can be represented by plane coefficients $(a_x, b_x, c_x, d_x)$. The normal of $P_x$ is denoted as $\vec{N}_x$. Under plane-based representation, a line $L$ can be represented by intersection of two planes $(P_m, P_n)$, or in short $L: (P_m, P_n)$. The positive direction of $L$ is defined by cross product of the normals of $P_a$ and $P_b$, that is, $\vec{L}=(a_m, b_m, c_m) \times (a_n, b_n, c_n)$. A point $p$ is represented by plane triples $(P_a, P_b, P_c)$, or in short $p: (P_a, P_b, P_c)$.

Given two points $p$ and $q$ in the same edge line $L: (P_u, P_v)$, the two points can be represented by plane triples $(P_u, P_v, P_p)$ and $(P_u, P_v, P_q)$, sharing the same first two components. We want to determine if $q$ is in positive side of $p$ along the $\vec{L}$. We call this two-point comparison. This predicates can be converted to the problem of orientation of a plane $P_p$ with respect to a point $q$, except that there is an extra request---we have to guarantee cosine between $\vec{L}$ and the normal $\vec{N}_p$ be positive, that is:
\begin{equation}
\label{eq:pointcomp}
   \left|
  \begin{array}{ccc}   %该矩阵一共3列，每一列都居中放置
  a_u  & b_u & c_u \\
  a_v  & b_v & c_v \\
  a_p  & b_p & c_p
  \end{array}
  \right| > 0,
\end{equation}
If not, we negate $P_p$ to be the test plane. The computation of this predicates is described in \cite{bernstein2009fast}.

Another predicates is used when tessellating a face (further explanation of its application is shown in Section \ref{}). Given two lines $L_a: (P_s, P_a)$ and $L_b: (P_s, P_b)$, which are on the same plane $P_s$, we want decide whether the sign of cross product of $\vec{L}_a$ and $\vec{L}_b$ has the same orientation as the normal $\vec{N}_s$. Direct solution requires to explicitly compute the vector of $L_a$ and $L_b$ and then decide the sign by $\vec{N}_s \cdot (\vec{L}_a \times \vec{L}_b)$. However, explicit representation of $\vec{L}_a$ and $\vec{L}_b$ requires more bits than standard double precision float point number, bringing extra computation burden.

To solve this, we decompose the normal vectors of $P_a$ and $P_b$: $\vec{N}_a = \vec{N}^\parallel_a + \vec{N}^\perp_a$ and $\vec{N}_b = \vec{N}^\parallel_b + \vec{N}^\perp_b$. Here superscript `$\parallel$` means the vector is in the plane $P_s$ and `$\perp$` means it is orthogonal to $P_s$. Then $\vec{N}_a \times \vec{N}_b = \vec{N}^\parallel_a \times \vec{N}^\parallel_b + \vec{N}^\perp_a \times \vec{N}^\parallel_b + \vec{N}^\parallel_a \times \vec{N}^\perp_b + \vec{N}^\perp_a \times \vec{N}^\perp_b$. As we know $\vec{N}^\perp_a$ and $\vec{N}^\perp_b$ is parallel, $\vec{N}^\perp_a \times \vec{N}^\perp_b = \textbf{0}$. Now, we evaluate the expression: $\vec{N}_s \cdot (\vec{N}_a \times \vec{N}_b)$. Since $\vec{N}_s$ is orthogonal to both $\vec{N}^\perp_a \times \vec{N}^\parallel_b $ and $\vec{N}^\parallel_a \times \vec{N}^\perp_b $, we deduce $\vec{N}_s \cdot (\vec{N}_a \times \vec{N}_b) = \vec{N}_s \cdot (\vec{N}^\parallel_a \times \vec{N}^\parallel_b)$. Here we make an essential observation that $\vec{N}^\parallel_a \times \vec{N}^\parallel_b$ has the same direction as $\vec{L}_a \times \vec{L}_b$, that is:
\begin{equation}
\label{eq:cosine}
sign(\vec{N}_s \cdot (\vec{N}_a \times \vec{N}_b)) = sign(\vec{N}_s \cdot (\vec{L}_a \times \vec{L}_b)),
\end{equation}
which means we do not need to explicitly compute $\vec{L}_a$ or $\vec{L}_b$. Instead, we only have to evaluate the left expression of equation \ref{eq:cosine}.

\section{Exact Intersection Detection}

\label{section:isect}
In this step, intersections between faces are computed through the triangle-triangle intersection test within each critical cell. We adopt M\"{o}ller's intersection detection algorithm \cite{moller1997fast} on account of its efficiency and simplicity. However, because collision detection algorithms are often accompanied by non-robustness problems, a conventional implementation of this algorithm may cause unpredictable results. Therefore, we integrate plane-based geometry representation \cite{sugihara1990solid} into M\"{o}ller's algorithm to make it unconditionally precise and robust. In the following, we first make a quick review of M\"{o}ller's algorithm, then discuss the way to make it unconditional robust. At last, we talk about how to deal with degenerate cases.

\subsection{Vertex-based method review}

\begin{figure}[t]
\centering
\includegraphics[width=2.5in]{projection}
\caption{$Seg_1$ is the intersection between $S_2$ and $F_1$. $Seg_2$ is the intersection between $S_1$ and $F_2$. The intersection between $F_1$ and $F_2$, which is the line segment in red, is the overlap of $Seg_1$ and $Seg_2$.}
\label{fig_projection}
\end{figure}


M\"{o}ller's algorithm computes the intersection between two triangles $F_1$ and $F_2$ in three steps (Fig. \ref{fig_projection}).
\begin{itemize}[leftmargin=0.45cm]
\item[1)] An early rejection is performed by testing whether $F_1$ intersects the plane where $F_2$ lies, which is denoted as $S_2$. This is a necessary condition of intersection between $F_1$ and $F_2$. If this test is passed, then the same is performed for $F_2$ and $S_1$, where $S_1$ is the plane of $F_1$.
\item[2)]The intersection between $F_1$ and $S_2$, denoted as $Seg_1$, and the intersection between $F_2$ and $S_1$, denoted as $Seg_2$, are separately computed .
 \item[3)]The intersection between $F_1$ and $F_2$ is determined by computing the overlap area of $Seg_1$ and $Seg_2$ .
\end{itemize}

\begin{figure}[t]
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=3.0in]{nonrobust}\\
  \caption{The left edges of A and B (\emph{left}) are nearly but not exactly collinear. However, under usual float point arithmetic, they might be judged as collinear causing discontinuous edges in the final result (\emph{right}).}\label{fig:precision}
\end{figure}


Conventional implementations of M\"{o}ller's algorithm use vertex-based representation and common float point arithmetic, which is neither exact nor robust. In Fig. \ref{fig:precision}, we illustrate a non-robust 2D case of the Boolean operation. Although implementing M\"{o}ller's algorithm with arbitrary precision arithmetic could make it robust, it is too costly for a large CSG evaluation. Actually, the non-robustness of this algorithm is from geometry \emph{constructions} \cite{bernstein2009fast}, which compute new coordinates of geometry objects based on the known coordinates of existing ones. In M\"{o}ller's algorithm, the coordinates of $Seg_1$ and $Seg_2$ (Fig. \ref{fig_projection}) are computed as intermediate results. On the other hand, if the computation can be restricted to \emph{predicates}, which make a two or three-way decision based on known coordinates, we could quickly and robustly implement this algorithm.



\subsection{Plane-based technique embedding}

\label{sec:embed}
According to the method described in section \ref{sec:convert}, triangle faces $f$ are firstly converted to its plane-based representation: a supporting plane $P_{s,f}$ surrounded by three bounding planes $P^i_{b,f}, i = 1,2,3$. We introduce the plane-based implementation of M\"{o}ller's algorithm step by step in the following:

\begin{figure}[t]
\centering
\includegraphics[width=3.5in]{sign}
\caption{We denote the signed distance from point $X$ to plane $S_2$ as $d_X$. All the four conditions of intersection between $F_1$ and $S_2$ (denoted as $Seg_1$) are:  (a) $d_A\cdot d_C<0$, $d_B\cdot d_C<0$; (b) $d_A=0$, $d_B=0$, $d_C\neq 0$; (c) $d_A=0$, $d_B\cdot d_C<0$; (d) $d_A=0$, $d_B\cdot d_C>0$. End points of $Seg_1$ are intersections between $S_2$ and related edge lines of $F_1$ (bold edges).}
\label{fig:isect}
\end{figure}



\begin{itemize}[leftmargin=0.45cm]
\item[1)] In this step, we only need to compute the orientation of a plane $(a, b, c, d)$
with respect to a point $(x, y, z)$, that is to compute:
\begin{equation}
sign(ax+by+cz+d).
\end{equation}
Using the notation in section \ref{sec:convert},  we know the coordinates of the points are precisely represented by $L$ bits. Also, after the conversion, the precisions of four coefficients of the supporting plane are $(P', P', P', P)$, where $P'=P-(L-1)-2$ and $P$ is defined in equation \ref{eq:precision}. Using the strengthened criterion $M \ge P+1$, we find that $M$ bits are enough to perform the predicates. This observation allow us to perform very efficient early discard on the triangle-triangle intersection test, which is the key idea to stay efficiency while perusing exactness.
\item[2)]In step 2, constructions are avoid by explicitly represent the end points of $Seg_1$ and $Seg_2$ using plane triples. As illustrated in Fig. \ref{fig:isect}(a), these points are the intersection between an edge line of a face and the supporting plane of the other face. Because the edge line of $f_1$ ($f_2$) can be represented as $[P_{s, f_1}, P^i_{b, f_1}]$ ($[P_{s, f_2}, P^i_{b, f_2}]$), the end points of $Seg_1$ ($Seg_2$) can be represented in the form of $[P_{s, f_1}, P_{s, f_2}, P^i_{b, f_2}]$ ($[P_{s, f_1}, P_{s, f_2}, P^i_{b, f_1}]$). In Fig. \ref{fig:isect}, we list all intersection situations between a triangle and a plane, and the corresponding bounding plane in each situation. Note, coplanar situation will be discussed later in section \ref{sec:degenerate}.
 \item[3)] The intersection between $f_1$ and $f_2$ is the overlap area of $Seg_1$ and $Seg_2$. It can be easily computed by comparing the end points of $Seg_1$ and $Seg_2$ along $L$ (Fig. \ref{fig_projection}), where $L$ is the intersection between $P_{s, f_1}$ and $P_{s, f_2}$. Because end points are all represented using plane triples, we can use the technique discussed in section \ref{sec:substrates} to implement the comparison.
\end{itemize}

\subsection{Intersection record}
\label{sec:ir}

The output of this stage, or what we call triangle-triangle intersection record (TTIR), is the data structure which organize the results of triangle-triangle intersection test. TTIR is also the input of tessellation, and is in deep couple with the tessellation method. It is hard to give full idea of how we design TTIR before we introduce our tessellation algorithm. We first give several requirements from tessellation stage, and then discuss the compositions of TTIR. To have a comprehensive understanding of TTIR, readers may need to review this section after finish reading section \ref{sec:tessellation}.

We recall our description of LHEC in section \ref{sec:meshes}, we need to transfer necessary information by TTIR to tessellation stage for LHEC construction. Necessary information includes:
\begin{itemize}
  \item The plane-based representation of intersection vertices.
  \item Intersection line segments, each consisting of references of two end points.
  \item Intersection context of the intersection line segments.
\end{itemize}

For example, assume two triangle faces $f_1$ and $f_2$, from primitive $A$ and $B$, intersect at line segment $(v_1, v_2)$, where $v_1$ and $v_2$ are references of two end points. First, $v_1$ and $v_2$ are introduced to $A$ and $B$, then intersection line segment $(v_1, v_2)$ is stored on both $f_1$ and $f_2$. At last, intersection context of $(v_1, v_2)$ is attached as an attribute. In this case, the intersection context of $(v_1, v_2)$  is $f_1$ for $A$ and $f_2$ for $B$.

In LHEC, there must not be any repetitive vertices within each LHEC or among LHECs in order to reconstruct the correct topology. Therefore, repetitive vertices elimination must be performed. Checking whether there are coincident points in a global scope can be quite inefficient. Fortunately, it is easy to figure out the location of an intersection vertex---whether it is inside, on a certain edge, or coincident with one of the three corners of intersection faces. Therefore, if we store the references of vertices on faces, edges, coincidence detection is localized and repetitive vertices elimination can be very fast.

// 区分context and plane representation


\subsection{Degenerate cases}
\label{sec:degenerate}

Before we discuss the degenerate cases, we give three principles for handling them. First, we want our method be unconditional robust and exact, so all degenerate cases should be well handled (completeness). Second, to control the complexity of tessellation, we want degenerate cases to be invisible to tessellation, that is, degenerate cases have the same format of output as non-degenerate cases (invisibility). Third, we want the outcome of tessellation be as simple as possible. That is, intersection line segments that will not help tessellation, if recognized, are disposed (simplicity).

To ensure the completeness, we classify all degenerate cases into three categories by the dimension of intersection:

\subsubsection{Intersects on point}
Point is degenerate case of line segment with zero length. The intersection point is potentially a vertex in the LHEC. There are two kinds of vertices, depending on whether the vertex is isolated. An isolated vertex does not need to participate tessellation. On the other side, if the intersection point is not isolated, it is end point of other intersection line segment and will be introduced when that intersection line segment is detected. Therefore, we treat the cases of intersection on point as non-intersection cases.

\subsubsection{Intersects on line segment}
This category is often not degenerate cases. However, when intersection line segment lies on a edge of one of the two triangle faces (Fig. \ref{fig:isect}b), error will occur if not careful. In this case, there will be another pair of triangle faces that will have exactly the same intersection line segment (Fig. \ref{fig:isect2}). This is what we called twin intersections. With twin intersections exist, one intersection line segment will be inserted twice, requiring extra effort to eliminate repetitions. To make things worse, the intersection will have different intersection contexts.

Twin intersection can be treated as union to resolve this.


\subsubsection{Coplanar}

\begin{figure}[t]
\centering
\includegraphics[width=3.5in]{degenerate}
\caption{}
\label{fig:isect2}
\end{figure}

Coplanar cases can also be seen as a special type of twin intersections. One is valid case, another is not.

\section{Deferred Tessellation}

\label{sec:tessellation}
This is the step to process TTIR and output LHIC, where the tessellation happens. We called this process as deferred tessellation because we do not tessellate until we collect all intersection line segments. For this problem, Ogayar-Anguita et. al. \cite{ogayar2015deferred} try to use Constrained Delaunay Triangulation (CDT) to solve, as the recorded intersection is naturally the constraints. It works fine for Boolean operation of two primitives. However, when there are more than two primitives, simply using CDT covers the complexity of tessellation. In such case, the intersection line segments may cross, overlap and even coincident with each other, introducing new vertex, splitting original intersection line segments. Naive implementation of CDT may lead to holes, repetitive edges, and other topology errors.

To solve these problems, we first refine the TTIR into an intermediate data structure---\emph{tessellation graph}. In this process, we resolve any intersection between intersection. After this, we tessellation each face according its corresponding tessellation graph. To make this process unconditional robust and exact, we utilize plane-based techniques and do not compute explicitly the coordinates of intersection points throughout this step.

\subsection{Tessellation graph}

TTIRs are only loose data that store the coordinates of intersection line segments. To perform tessellation and extract sub-faces, we need to organize TTIRs in a face scope. We use a graph-based data structure---tessellation graph---for this purpose. For each intersection face which needs tessellation, we construct tessellation graph. A tessellation graph is the graph-like description of the tessellated face topology. Nodes of tessellation graph represent vertices, and edges represent edges in LHIC. To avoid ambiguity, we call original three edges of the face as \emph{face boundaries} in the following. An important feature of tessellation graph is that it uses uniform representation for intersection vertices and line segments, and face boundaries and the original three corners. This dramatically reduces complexity of extracting sub-faces and allowing the following process simple and fast.


\subsubsection{Definition and construction}

Nodes of tessellation graph represent vertices and store the coordinates of them. Edges are nondirectional ones, and store the intersection context if exist. We classify graph edges into two types: we call edges on face boundaries as \emph{boundary edges} and edges inside face as \emph{inner edges}. They are different in at least two aspects: first, the boundary edges may not have a intersection context since it is not coincident with any TTIR; second, in the view of halfedge, inner edges represent two halfedges but boundary edges represent only one halfedge. The same classification is for intersection line segments: if the intersection are inside the face, it is an inner intersection, otherwise a boundary intersection. //可以提前到degenreate case

Recall our definition of TTIR in section \ref{sec:ir}, we find most of the work has already been done. To construct inner edges, we only need to first collect all vertices on the face (including both inside vertices and boundary vertices) to be the nodes, and then connect nodes by inner intersections. However, boundary edge construction is not that easy. We cannot simply connect the three face corners to be the boundary edges, since there may be boundary intersections, and face edges have to be splitted.

To construct boundary edges of graph, we first need to first sort vertices on each face edge along the edge line. This is done by two-point comparison in section \ref{sec:substrates}. After the sort, we connect the nodes by their sequence on the edge line to form the boundary edges. If any boundary edge is coincident with boundary intersection, we assign the intersection context of the boundary intersection to the boundary edge.

\subsubsection{Intersection refinement}

Since tessellation graph is a graph-like description of halfedge, it has extra constraints on its form. The most important one is that edges should not intersect each other. This can be guaranteed when there are only two primitives,  because the surface of primitives is all watertight, non-manifold, and without self-intersection. However, when there are more than two primitives, this constraint can be violated. In the view of intersection detection, it is not enough to find all intersection vertices by only triangle-triangle intersection test. This is because the new vertex can be formed not only by edge intersects plane, but also by three planes, which involves more than two triangles. Therefore, an extra processing--intersection refinement---is necessary to resolve these intersections before constructing tessellation graph.

Intersection refinement is performed between every two intersection line segments from different primitives. Using plane-based representation, whether two intersection line segments intersect is determined by predicate of orientation of plane against a point. For example, we want determine whether $I_v$: $(v_b, v_e, P_v, f_0, C_v)$ and $I_u$: $(u_b, u_e, P_u, f_0, C_u)$ intersects.
% 需要在IR那一章补充plane rep of intersection这一部分。intersection is describe with 四元组。
It is done by checking whether $u_b, u_e$ is on different sides of $P_v$ and whether $v_b, v_e$ is on different sides of $P_u$. If yes, $I_v$ and $I_u$ intersects and introduced new intersection vertex, which is the intersection of $P_u, P_v$ and the supporting plane $f_0$.

Degenerate cases will occur when $I_u$ and $I_v$ intersect on end point(s) or $I_v$ and $I_v$ are collinear.


\subsection{Extracting sub-faces}
The last step of tessellation is to really change the topology of input primitive to construct LHICs. We could apply CDT here since the intersection is refined and there is no intersection between the constraints. However, we choose to design a new method to extract sub-faces from intersection face for the efficiency:
\begin{itemize}
  \item lose topology information
  \item may not need to triangulate, classify in a whole
  \item hard to implement with planes
\end{itemize}

There is yet another problem on this method. Our method of extracting sub-faces assume that the tessellation graph is connected. However, this assumption can be false (Fig.).


\section{Face Classification}

\label{sec:classification}
As the final stage, face classification classify all candidate faces in linked halfedges, and decides which faces belong to the final mesh. Classification is done by evaluating the indicator vector of each face. During this process, we take advantage of plane-based representation to ensure unconditional correct classification. Also, as we maintain the geometry intra-primitive connectivity (by halfedge structure) and inter-primitive (by denoting shared vertex), we can utilize the space coherence of indicator vectors to accelerate this process.

In this section, we will first give a overall framework of face classification, then introduce how to classify each individual face. At last, we discuss how to accelerate this process by caching intermediate classification result.

\subsection{Basic idea}

The space coherence of indicator vectors means neighboring faces often have the same indicator vector, or share most components of indicator vectors. This means if we figure out the indicator vector of a face, we may know the indicator vectors of its neighboring faces instantly. In other cases, modification must be applied to the indicator vector. The necessary and sufficient condition of indicator change is that the two faces lie on different side of the primitive boundary. In our method, it means there will be intersection context on the shared edge of the two faces (section ??). Because the indicator change can be figured out  by the intersection context efficiently (section ??), we can classify all the faces of linked halfedges using flood-filling method.

The indicator vector of the first face is special. We can guarantee that the whole vector can be figured out only by intersection context of the face edges. Thus, point-in-polyhedron test is used for compensation. This works well under the assumption that the indicator of the sample point is the same with the face. For the point inside the face, the answer is absolutely yes, because the whole face must be classified as a whole. However, the coordinates of the inner points cannot be exactly represented, thus may lead to wrong predicates. Therefore, we choose to the use the face corners for point-in-polyhedron test. The test must be guaranteed to be exact, and, on the other hand, efficiency is not so important as we won't need many such tests. If ray-trace algorithm is used for the point-in-polyhedron test, the octree built during space division might be useful [].

However, use face corner instead of inner points has another problem. The indicator vector of the corner may not be the same as the of the indicator vector of the whole face. Figure ? shows such condition occurs when any of the face edge is on the boundary of other primitive. Nevertheless, we do not to worry about this. This is because when such case occurs, one of the edge adjacent to that corner will have intersection context to of that primitive, by which we can figure out the real indicator.

Another thing needs to be noticed is that the neighborhood of a certain face $f$ from primitive $A$ in linked halfedges does not only contain the face in $A$, but also include faces from other primitives which share edges with $f$. It can be efficiently found because in linked halfedges, coincident vertices between primitives are shared. Therefore, the indicator vector can be transfer not only intra-primitive, but also inter-primitive.

\subsection{Fast and exact face classification}

During flood-filling, we propagate the indicator vector of the current face $f_0$ to its neighboring faces, which have shared edges with the current face. If one of shared edges has intersection context $C_{I_v \mapsto A}$, it means the indicator of primitive $A$, denoted as $i_A$, could be different for the corresponding neighboring face $f_i$. In this section, we will show that $C_{I_v \mapsto A}$ is enough to compute the new $i_A$ for $f_i$. We only discuss the condition that $f_i$ is a triangle in the following. However, $f_i$ may not be triangle, not even a convex polygon. In these conditions, we can select a triangle subset of $f_i$ to represent $f_i$, since $f_i$ is guaranteed to be classified as a whole.

Feito et. al. had noticed that intersection neighborhood can be used for fast classification of faces around the intersection. According to their method, faces adjacent to intersection line segments must have neighbors from other primitive(s) that define the position and orientation for each other. Unfortunately, Feito et. al. did not give detail description of how to implement a exact classification, nor discuss about degenerate cases such as coplanar faces. As Feito et. al. use geometry connectivity for classification, any incorrect classification can be spread to neighborhoods, which may cause errors in a wide range.

We develop an exact and robust classification method based on the idea of using intersection neighborhood information. The intersection neighborhood is abstracted into two situations of intersection context (section ??). To make a clear description, we denote the three corners of neighboring face $f$ as $v_0^I$, $v_1^I$, $v_2$, where the superscript means the vertex lies on the intersection line segment $I$ with intersection context $C_{I \mapsto A}$. In the first situation, the intersection $I$ lies on the face of primitive $A$. That is, $C_{I \mapsto A} = f_x^A$. To calculate indicator $i_A$ for $f$, we only need to decide on which side of $f_x^A$ the current  face $f$ lies. Any sample point on $f$ except those on $I$ can be used for this predicates. As we can get the exact coordinates of corners, we choose $v_2$ to compute $i_A(f)$.

If $I$ lies on edge of primitive $A$,  the intersection context is face pair: $C_{I \mapsto A} = (f_p^A, f_q^A)$. This situation is a little more complex that we cannot decide $i_A$ until we check the orientations of both $f_p^A$ and $f_q^A$. To correctly classify $f$, we first build BSP structure using $f_p^A$ and $f_q^A$ [?], and then determine the space indicator $i_A(v_2)$ by the BSP. As coordinate of $v_2$ and all the planes can be exactly computed, the classification is exact. The indicator of the face $i_A(f)$ should be the same as $i_A (v_2)$. It is because under a BSP structure with only two division planes, any sample point on $f$ except those on $I$ has the same $\lambda_A$ (Fig. ??).


\subsection{Caching evaluation results}

If the CSG tree is large, with tens of, or even hundreds of nodes, computing $\lambda_\Phi(f) = \Phi(\vec{\lambda}(f))$ for every face can be costly. Considering the space coherence of indicator, we use cache techniques --- by storing the evaluation result of $\Phi$ --- to save the computation time.

The most simple cache strategy is final result cache. We know indicator vector $\vec{\lambda}$ will not change if there is no intersection context during spreading. That means the final classification $\lambda_\Phi$ will not change, too. Thus, those faces sharing the same $\lambda$ can be classified as a whole.

Also, we can also do intermediate result cache. It should be noticed that $\Phi(\vec{\lambda}(f))$ can be simplified if some components of $\vec{\lambda}$ is fixed. For example, assume we have a Boolean expression $M_1\cup (M_2\cap M_3-M_4)$. Given the values of two indicators $\lambda_1(x)=out$, $\lambda_2(x)=in$, the expression can be rewritten as $out\cup (in\cap M_3-M_4)$. Using the combination rules we can simplify the expression as $M_3-M_4$. This fact is important because for a large CSG tree, a certain primitive, denoted as $M_x$, often only intersects with a few other primitives $\Theta= \{M_{n_1}, M_{n_2}, \cdots, M_{n_k}\}$. That means all the faces in $M_x$ has the same indicators for the primitives not in $\Theta$. Therefore, we can first determine these fixed indicators and simplify the Boolean function $\Phi$ into a simpler one $\Phi_{M_x}$, and then use $\Phi_{M_x}$ to compute the final indicator for each faces.


\section{Experiments}



\section{Summary}

In this paper, we proposed a novel method to evaluate CSG with triangular mesh primitives. It is able to efficiently perform non-incremental evaluation of large CSG with massive faces. The key idea of our approach is to use the local coherence of face space labels to accelerate face membership classification. A two-level grouping framework is developed to group neighboring faces together and thus space labels can be shared within each group. This scheme saves much time for space label computation, which is often very time-consuming for conventional Boolean evaluation algorithms. Additionally, in order to be robust, plane-based geometry computation is introduced into the intersection computation step of our approach. Experiments have verified the proposed approach is more efficient than the state-of-the-art techniques while retaining robustness and stability. We will further investigate the robust tessellation in future.



\appendices



%\newpage
\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,citation}


%\newpage

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{rui}}]{Rui Wang}
is currently a postgraduate student at the Department of Computer Science and Technology, the Shanghai Jiao Tong University. His main research interests include real-time computer graphics and virtual reality applications.
\end{IEEEbiography}

% if you will not have a photo at all:
\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{xudong}}]{Xudong Jiang}
received his Master degree in Computer Science from Shanghai Jiao Tong University in 2014. He is currently working in Autodesk China Research \& Development Center. His research interest includes computer-aided geometric design and solid modeling.
\end{IEEEbiography}


\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{hongbo}}]{Hongbu Fu}
is an Associate Professor in the School of Creative Media, City University of Hong Kong. He received the PhD degree in computer science from the Hong Kong University of Science and Technology in 2007 and the BS degree in information sciences from Peking University, China, in 2002. His primary research interests fall in the fields of computer graphics and human computer interaction. He has served as an associate editor of The Visual Computer, Computers \& Graphics, and Computer Graphics Forum.
\end{IEEEbiography}


\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{sheng}}]{Bin Sheng}
received his BS degree in computer science from Huazhong University of Science and Technology in 2004, MS degree in software engineering from University of Macau in 2007, and PhD Degree in computer science from The Chinese University of Hong Kong in 2011. He is currently an associate professor in the Department of Computer Science and Engineering at Shanghai Jiao Tong University. His research interests include virtual reality, computer graphics, and image-based techniques.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{wu}}]{Enhua Wu}
received the BS degree from Tsinghua University in 1970, and the PhD degree from the University of Manchester (UK) in 1984. He is currently a research professor at the Institute of Software, Chinese Academy of Sciences, and Fellow of China Computer Federation. He has also been teaching at the University of Macau since 1997, where he is currently an Emeritus Professor. His research interests include realistic image synthesis, virtual reality, and scientific visualization. He has served as an associate editor of The Visual Computer, Computer Animation and Virtual Worlds.
\end{IEEEbiography}




\end{document}


